{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(15,8)})\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(15,8)})\n",
    "from datetime import datetime, timedelta\n",
    "from causalimpact import CausalImpact\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# helpers\n",
    "from helpers.wiki_gtrend_visualization import load_wikipedia_df\n",
    "from helpers.gtrend_visualization import load_gtrend_df, load_gtrend_hourly_df\n",
    "from helpers.load_topic_hourly import request_gtrends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv('data/tweets.csv', parse_dates=['date'], date_format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains all his tweets and retweets from 2009 to January, 8 2021 (one day before he was banned from Twitter) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-03-03 01:34:50')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.loc[1, 'date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's focus on the Covid period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>isRetweet</th>\n",
       "      <th>isDeleted</th>\n",
       "      <th>device</th>\n",
       "      <th>favorites</th>\n",
       "      <th>retweets</th>\n",
       "      <th>date</th>\n",
       "      <th>isFlagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1234653427789070336</td>\n",
       "      <td>I was thrilled to be back in the Great city of...</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>73748</td>\n",
       "      <td>17404</td>\n",
       "      <td>2020-03-03 01:34:50</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1218010753434820614</td>\n",
       "      <td>RT @CBS_Herridge: READ: Letter to surveillance...</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>7396</td>\n",
       "      <td>2020-01-17 03:22:47</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1304875170860015617</td>\n",
       "      <td>The Unsolicited Mail In Ballot Scam is a major...</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>80527</td>\n",
       "      <td>23502</td>\n",
       "      <td>2020-09-12 20:10:58</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1218159531554897920</td>\n",
       "      <td>RT @MZHemingway: Very friendly telling of even...</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>9081</td>\n",
       "      <td>2020-01-17 13:13:59</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1217962723234983937</td>\n",
       "      <td>RT @WhiteHouse: President @realDonaldTrump ann...</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>25048</td>\n",
       "      <td>2020-01-17 00:11:56</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                               text  \\\n",
       "1  1234653427789070336  I was thrilled to be back in the Great city of...   \n",
       "2  1218010753434820614  RT @CBS_Herridge: READ: Letter to surveillance...   \n",
       "3  1304875170860015617  The Unsolicited Mail In Ballot Scam is a major...   \n",
       "4  1218159531554897920  RT @MZHemingway: Very friendly telling of even...   \n",
       "5  1217962723234983937  RT @WhiteHouse: President @realDonaldTrump ann...   \n",
       "\n",
       "  isRetweet isDeleted              device  favorites  retweets  \\\n",
       "1         f         f  Twitter for iPhone      73748     17404   \n",
       "2         t         f  Twitter for iPhone          0      7396   \n",
       "3         f         f  Twitter for iPhone      80527     23502   \n",
       "4         t         f  Twitter for iPhone          0      9081   \n",
       "5         t         f  Twitter for iPhone          0     25048   \n",
       "\n",
       "                 date isFlagged  \n",
       "1 2020-03-03 01:34:50         f  \n",
       "2 2020-01-17 03:22:47         f  \n",
       "3 2020-09-12 20:10:58         f  \n",
       "4 2020-01-17 13:13:59         f  \n",
       "5 2020-01-17 00:11:56         f  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_covid_df = tweets_df[tweets_df['date'] >= '2019-12-01'].copy()\n",
    "tweets_covid_df.sort_values(by='date')\n",
    "tweets_covid_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Granger Causality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Extract Relevant Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the number of tweets where Hydroxychloroquine is mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets talking about Hydroxychloroquine is:  22\n"
     ]
    }
   ],
   "source": [
    "# Pinpoint all tweets containing the key words\n",
    "fake_news = ['Hydroxychloroquine', 'hydroxychloroquine']\n",
    "analyze = tweets_covid_df['text'].apply(lambda x: True if any(word in x for word in fake_news) else False)\n",
    "\n",
    "# Create a column with a boolean indicating whether tweet contains a key word\n",
    "new_col = analyze.reindex(tweets_covid_df.index, fill_value=False)\n",
    "tweets_covid_df['Hydroxychloroquine']=new_col\n",
    "\n",
    "print('Number of tweets talking about Hydroxychloroquine is: ', tweets_covid_df['Hydroxychloroquine'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2020-03-21\n",
       "1   2020-03-24\n",
       "2   2020-04-04\n",
       "3   2020-04-05\n",
       "4   2020-04-10\n",
       "Name: date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the datetimes where trump spoke about Hydroxychloroquine\n",
    "hydro_tweets_times = tweets_covid_df[tweets_covid_df['Hydroxychloroquine'] == True]['date'].copy()\n",
    "hydro_tweets_times = hydro_tweets_times.sort_values()\n",
    "hydro_tweets_times = hydro_tweets_times.reset_index(drop=True)\n",
    "hydro_tweets_times = hydro_tweets_times.dt.normalize() # set times to 00:00:00\n",
    "hydro_tweets_times.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Plot Wiki Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagename = 'Hydroxychloroquine'\n",
    "folder = 'data'\n",
    "filename = 'hydroxychloroquine'\n",
    "\n",
    "_, daily_wikipedia_hydro_df = load_wikipedia_df(folder,filename)\n",
    "\n",
    "daily_wikipedia_hydro_df = daily_wikipedia_hydro_df.drop('Week', axis=1)\n",
    "\n",
    "fig, axis = plt.subplots(figsize=(10,5))\n",
    "fig.tight_layout(pad=3.0)\n",
    "\n",
    "fig.suptitle('Daily searches related to {pagename} - Wikipedia'.format(pagename=pagename), size=20)\n",
    "fig.subplots_adjust(top=0.85)\n",
    "\n",
    "axis.set_title('Wikipedia', size=15)\n",
    "axis.set_ylabel('Relative search interest')\n",
    "axis.plot(daily_wikipedia_hydro_df['Views'])\n",
    "[axis.axvline(x=critical_date, color='red', linestyle='--') for critical_date in hydro_tweets_times]\n",
    "\n",
    "axis.set_xlabel('Date')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) Granger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the tweets in a format compatible with Granger causality analysis (i.e. time series)\n",
    "tweets_hydro_timeseries_df = pd.DataFrame(index=daily_wikipedia_hydro_df['Views'].index, columns=['Date'])\n",
    "\n",
    "for date in hydro_tweets_times:\n",
    "    tweets_hydro_timeseries_df[date] = (tweets_hydro_timeseries_df.index == date).astype(int)\n",
    "\n",
    "tweets_hydro_timeseries_df['Date'].fillna(0, inplace=True)\n",
    "tweets_hydro_timeseries_df['Tweet'] = tweets_hydro_timeseries_df.iloc[:, 1:].sum(axis=1)\n",
    "\n",
    "# Combine wiki and tweets\n",
    "wiki_tweets_hydro_df = daily_wikipedia_hydro_df.copy()\n",
    "wiki_tweets_hydro_df['Tweets'] = tweets_hydro_timeseries_df['Tweet']\n",
    "wiki_tweets_hydro_df['Tweets'].fillna(0, inplace=True)\n",
    "display(wiki_tweets_hydro_df.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Granger test between GTrends views and tweets\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "\n",
    "print(\"DO VIEWS CAUSE TWEETS?\")\n",
    "grangercausalitytests(wiki_tweets_hydro_df, 2)\n",
    "\n",
    "print('\\n --------------------------------')\n",
    "print(\"\\n DO TWEETS CAUSE VIEWS?\")\n",
    "tweets_cause_views_gtrends = grangercausalitytests(wiki_tweets_hydro_df[['Tweets', 'Views']], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Causal Impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Plot GTrends Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagename = 'Hydroxychloroquine'\n",
    "folder = 'data'\n",
    "filename = 'hydroxychloroquine'\n",
    "\n",
    "hydro_gtrends_df = load_gtrend_df(folder, filename)\n",
    "\n",
    "fig, axis = plt.subplots(figsize=(10,5))\n",
    "fig.tight_layout(pad=3.0)\n",
    "\n",
    "fig.suptitle('Weekly searches related to {pagename} - Google Trends'.format(pagename=pagename), size=20)\n",
    "fig.subplots_adjust(top=0.85)\n",
    "\n",
    "axis.set_title('Google Trends', size=15)\n",
    "axis.set_ylabel('Relative search interest')\n",
    "axis.plot(hydro_gtrends_df['Views'])\n",
    "[axis.axvline(x=critical_date, color='red', linestyle='--') for critical_date in hydro_tweets_times]\n",
    "\n",
    "axis.set_xlabel('Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Fetch GTrends Time Series at Hourly Granularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet time: 2020-03-21 00:00:00\n",
      "start time: 2020-03-19 00:00:00\n",
      "end time: 2020-03-23 00:00:00\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/hydroxychloroquine/hydroxychloroquine_googletrends_tweet_0.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/sabri/Projects/ada_m3/sabri.ipynb Cell 23\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sabri/Projects/ada_m3/sabri.ipynb#X31sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m filename \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mhydroxychloroquine\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sabri/Projects/ada_m3/sabri.ipynb#X31sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m pagename \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mHydroxychloroquine\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/sabri/Projects/ada_m3/sabri.ipynb#X31sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m request_gtrends(folder, filename, alias, pagename, start_time, end_time)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sabri/Projects/ada_m3/sabri.ipynb#X31sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Control data\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sabri/Projects/ada_m3/sabri.ipynb#X31sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m folder \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m~/Projects/ada_m3/helpers/load_topic_hourly.py:27\u001b[0m, in \u001b[0;36mrequest_gtrends\u001b[0;34m(folder, filename, alias, pagename, start_time, end_time)\u001b[0m\n\u001b[1;32m     23\u001b[0m results \u001b[39m=\u001b[39m search\u001b[39m.\u001b[39mget_dict()\n\u001b[1;32m     25\u001b[0m json_object \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mdumps(results)\n\u001b[0;32m---> 27\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(saving_path, \u001b[39m'\u001b[39;49m\u001b[39mw\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     28\u001b[0m     f\u001b[39m.\u001b[39mwrite(json_object)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/hydroxychloroquine/hydroxychloroquine_googletrends_tweet_0.json'"
     ]
    }
   ],
   "source": [
    "# QUESTION (SABRI): SHOULD WE KEEP THIS IN THE NOTEBOOK?\n",
    "\n",
    "# Select tweet number\n",
    "tweet_nb = 0\n",
    "alias = f\"tweet_{tweet_nb}\"\n",
    "\n",
    "# Request data from GTrends API (both hydro and Google) and save it\n",
    "tweet_time = hydro_tweets_times[tweet_nb].replace(minute=0, second=0)\n",
    "print(f\"Tweet time: {tweet_time}\")\n",
    "start_time = tweet_time - timedelta(hours=48)\n",
    "end_time = tweet_time + timedelta(hours=48)\n",
    "\n",
    "print(f\"start time: {start_time}\")\n",
    "print(f\"end time: {end_time}\")\n",
    "\n",
    "# Hydro data \n",
    "folder = 'data'\n",
    "filename = 'hydroxychloroquine'\n",
    "pagename = 'Hydroxychloroquine'\n",
    "request_gtrends(folder, filename, alias, pagename, start_time, end_time)\n",
    "\n",
    "# Control data\n",
    "folder = 'data'\n",
    "filename = 'climate'\n",
    "pagename = 'Climate'\n",
    "request_gtrends(folder, filename, alias, pagename, start_time, end_time)\n",
    "\n",
    "folder = 'data'\n",
    "filename = 'coffee'\n",
    "pagename = 'Coffee'\n",
    "request_gtrends(folder, filename, alias, pagename, start_time, end_time)\n",
    "\n",
    "folder = 'data'\n",
    "filename = 'news'\n",
    "pagename = 'News'\n",
    "request_gtrends(folder, filename, alias, pagename, start_time, end_time)\n",
    "\n",
    "folder = 'data'\n",
    "filename = 'shop'\n",
    "pagename = 'Shop'\n",
    "request_gtrends(folder, filename, alias, pagename, start_time, end_time)\n",
    "\n",
    "folder = 'data'\n",
    "filename = 'time'\n",
    "pagename = 'Time'\n",
    "request_gtrends(folder, filename, alias, pagename, start_time, end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load hydro json\n",
    "folder = 'data'\n",
    "filename = 'hydroxychloroquine'\n",
    "gtrends_hydro_df = load_gtrend_hourly_df(folder, filename, alias)\n",
    "\n",
    "# Load control json\n",
    "folder = 'data'\n",
    "filename = 'climate'\n",
    "gtrends_climate_df = load_gtrend_hourly_df(folder, filename, alias)\n",
    "\n",
    "folder = 'data'\n",
    "filename = 'coffee'\n",
    "gtrends_coffee_df = load_gtrend_hourly_df(folder, filename, alias)\n",
    "\n",
    "folder = 'data'\n",
    "filename = 'news'\n",
    "gtrends_news_df = load_gtrend_hourly_df(folder, filename, alias)\n",
    "folder = 'data'\n",
    "filename = 'shop'\n",
    "gtrends_shop_df = load_gtrend_hourly_df(folder, filename, alias)\n",
    "\n",
    "folder = 'data'\n",
    "filename = 'time'\n",
    "gtrends_time_df = load_gtrend_hourly_df(folder, filename, alias)\n",
    "\n",
    "# Combine the dataframes\n",
    "gtrends_df = pd.concat([gtrends_hydro_df, gtrends_climate_df, gtrends_coffee_df, \n",
    "                        gtrends_news_df, gtrends_shop_df, gtrends_time_df],\n",
    "                         axis=1, keys=['hydro', 'climate', 'coffee', 'news',\n",
    "                                        'shop', 'time'])\n",
    "gtrends_df.columns = gtrends_df.columns.droplevel(1)\n",
    "\n",
    "gtrends_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) Causal Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose pre and post-periods\n",
    "pre_period = [gtrends_df.index[0], tweet_time]\n",
    "post_period = [tweet_time+timedelta(hours=1), gtrends_df.index[-1]]\n",
    "print(pre_period)\n",
    "print(post_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify assumptions on pre-period: linear regression\n",
    "mod = smf.ols(formula='hydro ~ coffee + climate + news + shop + time', data=gtrends_df[:pre_period[1]])\n",
    "res = mod.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conduct causal\n",
    "impact = CausalImpact(data = gtrends_df, pre_period=pre_period, post_period=post_period, prior_level_sd=None, model_args={'dynamic_regression': True})\n",
    "impact.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D) Alternative Hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SABRI QUESTION: KEEP?\n",
    "# Request data from GTrends API (both hydro and Google) and save it\n",
    "treatment_time = pd.Timestamp(2020,3,16,18,0,0)\n",
    "print(f\"Tweet time: {treatment_time}\")\n",
    "start_time = pd.Timestamp(2020,3,15,12,0,0)\n",
    "end_time = pd.Timestamp(2020,3,19,12,0,0)\n",
    "\n",
    "print(f\"start time: {start_time}\")\n",
    "print(f\"end time: {end_time}\")\n",
    "\n",
    "alias = \"publi\"\n",
    "\n",
    "# Hydro data \n",
    "# folder = 'data'\n",
    "# filename = 'hydroxychloroquine'\n",
    "# pagename = 'Hydroxychloroquine'\n",
    "# request_gtrends(folder, filename, alias, pagename, start_time, end_time)\n",
    "\n",
    "# # Control data\n",
    "# folder = 'data'\n",
    "# filename = 'climate'\n",
    "# pagename = 'Climate'\n",
    "# request_gtrends(folder, filename, alias, pagename, start_time, end_time)\n",
    "\n",
    "# folder = 'data'\n",
    "# filename = 'coffee'\n",
    "# pagename = 'Coffee'\n",
    "# request_gtrends(folder, filename, alias, pagename, start_time, end_time)\n",
    "\n",
    "# folder = 'data'\n",
    "# filename = 'news'\n",
    "# pagename = 'News'\n",
    "# request_gtrends(folder, filename, alias, pagename, start_time, end_time)\n",
    "\n",
    "# folder = 'data'\n",
    "# filename = 'shop'\n",
    "# pagename = 'Shop'\n",
    "# request_gtrends(folder, filename, alias, pagename, start_time, end_time)\n",
    "\n",
    "# folder = 'data'\n",
    "# filename = 'time'\n",
    "# pagename = 'Time'\n",
    "# request_gtrends(folder, filename, alias, pagename, start_time, end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load hydro json\n",
    "folder = 'data'\n",
    "filename = 'hydroxychloroquine'\n",
    "gtrends_hydro_df = load_gtrend_hourly_df(folder, filename, alias)\n",
    "\n",
    "# Load control json\n",
    "folder = 'data'\n",
    "filename = 'climate'\n",
    "gtrends_climate_df = load_gtrend_hourly_df(folder, filename, alias)\n",
    "\n",
    "folder = 'data'\n",
    "filename = 'coffee'\n",
    "gtrends_coffee_df = load_gtrend_hourly_df(folder, filename, alias)\n",
    "\n",
    "folder = 'data'\n",
    "filename = 'news'\n",
    "gtrends_news_df = load_gtrend_hourly_df(folder, filename, alias)\n",
    "\n",
    "folder = 'data'\n",
    "filename = 'shop'\n",
    "gtrends_shop_df = load_gtrend_hourly_df(folder, filename, alias)\n",
    "\n",
    "folder = 'data'\n",
    "filename = 'time'\n",
    "gtrends_time_df = load_gtrend_hourly_df(folder, filename, alias)\n",
    "\n",
    "display(gtrends_climate_df)\n",
    "display(gtrends_coffee_df)\n",
    "\n",
    "# Combine the dataframes\n",
    "gtrends_df = pd.concat([gtrends_hydro_df, gtrends_climate_df, gtrends_coffee_df, \n",
    "                        gtrends_news_df, gtrends_shop_df, gtrends_time_df],\n",
    "                         axis=1, keys=['hydro', 'climate', 'coffee', 'news',\n",
    "                                        'shop', 'time'])\n",
    "gtrends_df.columns = gtrends_df.columns.droplevel(1)\n",
    "\n",
    "gtrends_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose pre and post-periods\n",
    "pre_period = [gtrends_df.index[0], treatment_time]\n",
    "post_period = [treatment_time+timedelta(hours=1), gtrends_df.index[-1]]\n",
    "print(pre_period)\n",
    "print(post_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify assumptions on pre-period: linear regression\n",
    "mod = smf.ols(formula='hydro ~ coffee + climate + news + shop + time', data=gtrends_df[:pre_period[1]])\n",
    "res = mod.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conduct causal\n",
    "impact = CausalImpact(data = gtrends_df, pre_period=pre_period, post_period=post_period, prior_level_sd=None, model_args={'dynamic_regression': True})\n",
    "impact.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
